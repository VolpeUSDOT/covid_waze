SELECT A.*, B.PERCENTILE, B.RD_DEFICIENT, B.BASIC_ID FROM SMARTWAY_JOIN_MCMIS A,
CSA.HIST_CARRIER_MEASURE B,
(SELECT DOT_NUMBER, ROUND(NVL(fatal_crash_total,0)/AVG_POWER_UNIT,2) FATAL_CR,
ROUND(NVL(inj_crash_total,0)/AVG_POWER_UNIT,2) INJURY_CR,
ROUND(NVL(towaway_crash_total,0)/AVG_POWER_UNIT,2) TOWAWAY_CR
FROM CSA.HIST_CARRIER) C
WHERE A.DOT_NUMBER = B.DOT_NUMBER
AND A.DOT_NUMBER = C.DOT_NUMBER
AND B.RELEASED_ID = 181
)
SELECT *
FROM my_data
PIVOT (
MAX( PERCENTILE) As PERCENTILE,
MAX( RD_DEFICIENT ) as RD_DEFICIENT
FOR BASIC_ID IN (11 as UD, 12 As HOS , 13 As DA, 14 AS DF, 15 AS VM, 16 AS HM)
)
ORDER BY DOT_NUMBER") # Jessie created a table in her schema.
census <- dbGetQuery(conn = con, statement = qry)
dim(census) #2871   18
names(census)
census$Utlization <- census$RECENT_MILEAGE/census$AVG_POWER_UNIT
census$CARRIER_GROUP_ID <- as.factor(census$CARRIER_GROUP_ID)
# Crash rate by ranking and category ----
qry <- paste0("SELECT GM_CO2_RANK, SMARTWAY_RANKING_CATEGORY,
--CASE WHEN GM_CO2_RANK IN (1,2,3,4) THEN 'HIGH' ELSE 'LOW' END RANK,
CASE WHEN GM_CO2_RANK IN (1) THEN 'HIGH' ELSE 'LOW' END RANK,
COUNT(*) NBR_CARRIER
, SUM(AVG_POWER_UNIT) PU, ROUND(SUM(AVG_POWER_UNIT)/COUNT(*),2) AVG_PU, SUM(CRASH_TOTAL) CRASH
, ROUND(SUM(CRASH_TOTAL)*100/SUM(AVG_POWER_UNIT),2) CRASH_RATE
, ROUND(SUM(fatal_crash_total)*100/SUM(AVG_POWER_UNIT),2) FATAL_CRASH_RATE
, ROUND(SUM(inj_crash_total)*100/SUM(AVG_POWER_UNIT),2) INJURY_CRASH_RATE
, ROUND(SUM(towaway_crash_total)*100/SUM(AVG_POWER_UNIT),2) TOWAWAY_CRASH_RATE
FROM JESSIEYANG.SMARTWAY_JOIN_MCMIS
WHERE passes_crash_filter = 'Y'
GROUP BY GM_CO2_RANK, SMARTWAY_RANKING_CATEGORY
ORDER BY GM_CO2_RANK, SMARTWAY_RANKING_CATEGORY"
)
cr_rank_cat <- dbGetQuery(conn = con, statement = qry)
dim(cr_rank_cat) #62*11
qry <- paste0("SELECT GTM_CO2_RANK, SMARTWAY_RANKING_CATEGORY,
--CASE WHEN GM_CO2_RANK IN (1,2,3,4) THEN 'HIGH' ELSE 'LOW' END RANK,
CASE WHEN GTM_CO2_RANK IN (1) THEN 'HIGH' ELSE 'LOW' END RANK,
COUNT(*) NBR_CARRIER
, SUM(AVG_POWER_UNIT) PU, ROUND(SUM(AVG_POWER_UNIT)/COUNT(*),2) AVG_PU, SUM(CRASH_TOTAL) CRASH
, ROUND(SUM(CRASH_TOTAL)*100/SUM(AVG_POWER_UNIT),2) CRASH_RATE
, ROUND(SUM(fatal_crash_total)*100/SUM(AVG_POWER_UNIT),2) FATAL_CRASH_RATE
, ROUND(SUM(inj_crash_total)*100/SUM(AVG_POWER_UNIT),2) INJURY_CRASH_RATE
, ROUND(SUM(towaway_crash_total)*100/SUM(AVG_POWER_UNIT),2) TOWAWAY_CRASH_RATE
FROM JESSIEYANG.SMARTWAY_JOIN_MCMIS
WHERE passes_crash_filter = 'Y'
GROUP BY GTM_CO2_RANK, SMARTWAY_RANKING_CATEGORY
ORDER BY GTM_CO2_RANK, SMARTWAY_RANKING_CATEGORY"
)
cr_rank_cat_gtm <- dbGetQuery(conn = con, statement = qry)
dim(cr_rank_cat) #62*11
# Crash rate by ranking and category and carrier type/size ----
qry <- paste0("SELECT GM_CO2_RANK, SMARTWAY_RANKING_CATEGORY, CARRIER_GROUP_ID, PU_GROUP,
--CASE WHEN GM_CO2_RANK IN (1,2,3,4) THEN 'HIGH' ELSE 'LOW' END RANK,
CASE WHEN GM_CO2_RANK IN (1) THEN 'HIGH' ELSE 'LOW' END RANK,
COUNT(*) NBR_CARRIER
, SUM(AVG_POWER_UNIT) PU, ROUND(SUM(AVG_POWER_UNIT)/COUNT(*),2) AVG_PU, SUM(CRASH_TOTAL) CRASH
, ROUND(SUM(CRASH_TOTAL)*100/SUM(AVG_POWER_UNIT),2) CRASH_RATE
, ROUND(SUM(fatal_crash_total)*100/SUM(AVG_POWER_UNIT),2) FATAL_CRASH_RATE
, ROUND(SUM(inj_crash_total)*100/SUM(AVG_POWER_UNIT),2) INJURY_CRASH_RATE
, ROUND(SUM(towaway_crash_total)*100/SUM(AVG_POWER_UNIT),2) TOWAWAY_CRASH_RATE
FROM JESSIEYANG.SMARTWAY_JOIN_MCMIS
WHERE passes_crash_filter = 'Y'
GROUP BY GM_CO2_RANK, SMARTWAY_RANKING_CATEGORY,CARRIER_GROUP_ID, PU_GROUP
ORDER BY GM_CO2_RANK, SMARTWAY_RANKING_CATEGORY,CARRIER_GROUP_ID, PU_GROUP"
)
cr_type_size <- dbGetQuery(conn = con, statement = qry)
cr_type_size$CARRIER_GROUP_ID <- as.factor(cr_type_size$CARRIER_GROUP_ID)
dim(cr_type_size) #62*11
# each category - individual graph - GM
ggplot(cr_rank_cat, aes(GM_CO2_RANK, CRASH_RATE, colour = SMARTWAY_RANKING_CATEGORY)) +
geom_line() + geom_point(aes(size = NBR_CARRIER)) +
facet_wrap(~ SMARTWAY_RANKING_CATEGORY)+
theme(legend.position="none")
# each category - individual graph - GM
ggplot(cr_rank_cat %>% filter(!SMARTWAY_RANKING_CATEGORY %in% c('Package')), aes(GM_CO2_RANK, CRASH_RATE, colour = SMARTWAY_RANKING_CATEGORY)) +
geom_line() + geom_point(aes(size = NBR_CARRIER)) +
facet_wrap(~ SMARTWAY_RANKING_CATEGORY)+
theme(legend.position="none")
# each category - individual graph - GTM
ggplot(cr_rank_cat_gtm, aes(GTM_CO2_RANK, CRASH_RATE, colour = SMARTWAY_RANKING_CATEGORY)) +
geom_line() + geom_point(aes(size = NBR_CARRIER)) +
facet_wrap(~ SMARTWAY_RANKING_CATEGORY)+
theme(legend.position="none")
# each category - individual graph
ggplot(cr_rank_cat %>% filter(SMARTWAY_RANKING_CATEGORY %in% c('TL/Dry Van', 'Refrigerated','Mixed','Flatbed')), aes(GM_CO2_RANK, CRASH_RATE, colour = SMARTWAY_RANKING_CATEGORY)) +
geom_line() + geom_point(aes(size = NBR_CARRIER)) +
facet_wrap(~ SMARTWAY_RANKING_CATEGORY)+
theme(legend.position="none")
#,'Expedited','LTL/Dry Van'
# each category - individual graph - GTM
ggplot(cr_rank_cat_gtm %>% filter(SMARTWAY_RANKING_CATEGORY %in% c('TL/Dry Van', 'Refrigerated','Mixed','Flatbed')), aes(GTM_CO2_RANK, CRASH_RATE, colour = SMARTWAY_RANKING_CATEGORY)) +
geom_line() + geom_point(aes(size = NBR_CARRIER)) +
facet_wrap(~ SMARTWAY_RANKING_CATEGORY)+
theme(legend.position="none")
g1 <- ggplot(cr_rank_cat %>% filter(SMARTWAY_RANKING_CATEGORY %in% c('Expedited','LTL/Dry Van')), aes(GM_CO2_RANK, CRASH_RATE, colour = SMARTWAY_RANKING_CATEGORY)) +
geom_line() + geom_point(aes(size = NBR_CARRIER)) +
facet_wrap(~ SMARTWAY_RANKING_CATEGORY)+
theme(legend.position="none")
g2<- ggplot(cr_rank_cat_gtm %>% filter(SMARTWAY_RANKING_CATEGORY %in% c('Expedited','LTL/Dry Van')), aes(GTM_CO2_RANK, CRASH_RATE, colour = SMARTWAY_RANKING_CATEGORY)) +
geom_line() + geom_point(aes(size = NBR_CARRIER)) +
facet_wrap(~ SMARTWAY_RANKING_CATEGORY)+
theme(legend.position="none")
ggpubr::ggarrange(bxp, dp, lp,
ncol = 1, nrow = 2)
library(ggpubr)
ggarrange(g1,g2,ncol = 1, nrow = 2)
# Grab data from auto-export bucket and save to both local machine and network drive (for BTS outputs)
# Depends on proper setup of SDC authentication script. Permissions are granted by SDC administrators.
# Buckets updated for ECS
# The auth script is a Python script. We can call it in R using reticulate. This depends on a miniconda installation at
# C:/Users/{user.name}/AppData/Local/r-miniconda, or you can choose another version of Python installed. See miniconda_path().
# See https://rstudio.github.io/reticulate/articles/python_packages.html
library(reticulate) # help set up python environment in R
# First time: Install the conda environment with necessary packages
if(!dir.exists(
file.path(dirname(path.expand('~/')),
'AppData', 'Local', 'r-miniconda'))) {
conda_create('r-reticulate')
conda_install(envname = 'r-reticulate', packages = c('requests', 'configparser'))
}
# Setup the paths to work in
auto_export_bucket = 's3://prod-sdc-waze-autoexport-004118380849/alert/'
volpe_drive = '//vntscex.local/DFS/Projects/PROJ-OS62A1/SDI Waze Phase 2/Output/COVID'
use_date = Sys.Date()#  -1
local_dir = file.path('Output', use_date)
if (!dir.exists(local_dir)) {
dir.create(local_dir, recursive = T)
}
# Fetch data by refreshing token in Python using Reticulate ----
if(!file.exists(file.path(path.expand(getwd()),
'utility',
'auto_export_waze.py'))){
stop('Contact sdc-support@dot.gov to set up auto-export permissions and be given the appropriate authentication script.')
}
# Refresh credentials
reticulate::source_python(file = file.path(path.expand(getwd()),
'utility',
'auto_export_waze.py'))
system(
paste0('aws --profile sdc-token s3 ls ', auto_export_bucket, use_date, '/')) # review the file directory of the folder in SDC bucket.
# Files to get
get_files = c('Waze_2020_MSA_day.csv',
'Waze_2020_MSA_week.csv',
'Waze_2020_National_day.csv',
'Waze_2020_National_week.csv',
paste0('Waze_Covid_joined_', use_date, '.csv'))
for(file in get_files){
if(grepl(use_date, file)){
out_file = 'Waze_Full.csv'
} else {
out_file = file
}
system(
paste0('aws --profile sdc-token s3 cp ',
auto_export_bucket,
use_date, '/',
file,
' ',
path.expand(local_dir), '/',
out_file)
)
}
# Produce weekly index calculations ----
source('Analysis/Waze_Index_Calcs_Check.R')
# Replace files on Volpe shared drive for Tableau ----
# Too slow. Just copy manually.
# # Check to see if on the VPN
# if(dir.exists(volpe_drive)){
#
#   for(file in get_files){
#     print(paste('Copying', file))
#
#     file.copy(from = file.path(path.expand(local_dir), file),
#               to = file.path(volpe_drive, file),
#               overwrite = TRUE)
#
#     print('... done \n')
#     }
#
#   } else {
#
#     print('Connect to VPN and verify access to Volpe shared drive')
#
#   }
# setup ----
library(tidyverse)
library(lubridate)
library(readr)
input.loc = 'Data'
output.loc = 'Output'
drive.output = '//vntscex.local/DFS/Projects/PROJ-OS62A1/SDI Waze Phase 2/Data/COVID'
latest_refresh_day = max(dir('Output')[grep(format(Sys.Date(), '%Y'), dir('Output'))]) # e.g. '2020-05-06'
cat(latest_refresh_day)
# setup ----
library(tidyverse)
library(lubridate)
library(readr)
input.loc = 'Data'
output.loc = 'Output'
drive.output = '//vntscex.local/DFS/Projects/PROJ-OS62A1/SDI Waze Phase 2/Data/COVID'
latest_refresh_day = max(dir('Output')[grep(format(Sys.Date(), '%Y'), dir('Output'))]) # e.g. '2020-05-06'
cat(latest_refresh_day)
nw <- read_csv(file.path(output.loc, latest_refresh_day, 'Waze_2020_National_week.csv'))
nd <- read_csv(file.path(output.loc, latest_refresh_day, 'Waze_2020_National_day.csv'))
# Daily MSA
d_MSA_day <- read_csv(file.path(output.loc, latest_refresh_day, 'Waze_2020_MSA_day.csv'),
col_types = cols(dowavg19_ACCIDENT = col_double(),
dowavg19_JAM = col_double(),
dowavg19_WEATHERHAZARD = col_double(),
bl2020_mean_ACCIDENT = col_double(),
bl2020_mean_JAM = col_double(),
bl2020_mean_WEATHERHAZARD = col_double()
))
d_MSA_week <- read_csv(file.path(output.loc, latest_refresh_day, 'Waze_2020_MSA_week.csv'),
col_types = cols(weeksum19_ACCIDENT = col_double(),
weeksum19_JAM = col_double(),
weeksum19_WEATHERHAZARD = col_double(),
bl2020_mean_ACCIDENT = col_double(),
bl2020_mean_JAM = col_double(),
bl2020_mean_WEATHERHAZARD = col_double()
))
nw <- nw %>%
ungroup %>%
group_by(year, week) %>%
mutate(WoY_Weight_Jams_19 = weeksum19_JAM_nf / sum(weeksum19_JAM_nf, na.rm=T),
WoY_Weight_Crash_19 = weeksum19_ACCIDENT_nf / sum(weeksum19_ACCIDENT_nf, na.rm=T),
WoY_Weight_Jams_bl = bl2020_mean_JAM_nf / sum(bl2020_mean_JAM_nf, na.rm=T),
WoY_Weight_Crash_bl = bl2020_mean_ACCIDENT_nf / sum(bl2020_mean_ACCIDENT_nf, na.rm=T),
WoY_Weight_Jams_lag1 = lag1_weeksum20_JAM_nf / sum(lag1_weeksum20_JAM_nf, na.rm=T),
WoY_Weight_Crash_lag1 = lag1_weeksum20_ACCIDENT_nf / sum(lag1_weeksum20_ACCIDENT_nf, na.rm=T)
) %>%
ungroup()
week_index_calcs <- nw %>%
ungroup() %>%
mutate(
pct_ch_from_prev_week_jam = 100 *  ( (weeksum20_JAM_nf - lag1_weeksum20_JAM_nf) / lag1_weeksum20_JAM_nf ),
pct_ch_from_prev_week_crash = 100 *  ( (weeksum20_ACCIDENT_nf - lag1_weeksum20_ACCIDENT_nf) / lag1_weeksum20_ACCIDENT_nf ),
pct_ch_from_2019_week_jam = 100 *  ( (weeksum20_JAM_nf - weeksum19_JAM_nf) / weeksum19_JAM_nf ),
pct_ch_from_2019_week_crash = 100 *  ( (weeksum20_ACCIDENT_nf - weeksum19_ACCIDENT_nf) / weeksum19_ACCIDENT_nf ),
pct_ch_from_2020bl_week_jam = 100 *  ( (weeksum20_JAM_nf - bl2020_mean_JAM_nf) / bl2020_mean_JAM_nf ),
pct_ch_from_2020bl_week_crash = 100 *  ( (weeksum20_ACCIDENT_nf - bl2020_mean_ACCIDENT_nf) / bl2020_mean_ACCIDENT_nf )
) %>%
group_by(year, week) %>%
summarize(
weekly_sum_20_jam = sum(weeksum20_JAM_nf, na.rm = T),
weekly_sum_19_jam = sum(weeksum19_JAM_nf, na.rm = T),
change_from_19_jam = 100 * (weekly_sum_20_jam - weekly_sum_19_jam) / weekly_sum_19_jam,
pct_ch_from_prev_week_jam = weighted.mean(pct_ch_from_prev_week_jam, w = WoY_Weight_Jams_lag1),
#pct_ch_from_prev_week_crash = weighted.mean(pct_ch_from_prev_week_crash, w = WoY_Weight_Crash_lag1),
pct_ch_from_2019_week_jam = weighted.mean(pct_ch_from_2019_week_jam, w = WoY_Weight_Jams_19),
#pct_ch_from_2019_week_crash = weighted.mean(pct_ch_from_2019_week_crash, w = WoY_Weight_Crash_19),
pct_ch_from_2020bl_week_jam = weighted.mean(pct_ch_from_2020bl_week_jam, w = WoY_Weight_Jams_bl),
#pct_ch_from_2020bl_week_crash = weighted.mean(pct_ch_from_2020bl_week_crash, w = WoY_Weight_Crash_bl),
)
write.csv(week_index_calcs, file = file.path(drive.output, 'Weekly_Covid_Outputs.csv'), row.names = F)
# look for leap years
days_in_year_20 = ifelse(lubridate::days_in_month('2020-02-01') == 29, 366, 365)
days_in_year_21 = ifelse(lubridate::days_in_month('2021-02-01') == 29, 366, 365)
days_in_year_22 = ifelse(lubridate::days_in_month('2022-02-01') == 29, 366, 365)
dates = c(paste('2020', formatC(1:days_in_year_20, width = 2, flag = '0'), sep = '-'),
paste('2021', formatC(1:days_in_year_21, width = 2, flag = '0'), sep = '-'),
paste('2022', formatC(1:days_in_year_21, width = 2, flag = '0'), sep = '-'))
dates = strptime(dates, '%Y-%j')
week = lubridate::epiweek(dates)
weeklookup = data.frame(dates, year = format(dates, '%Y'), week)
week_end_date = weeklookup %>%
mutate(weekchange = week - lead(week)) %>%
filter(weekchange != 0) %>%
select(-weekchange) %>%
mutate(year = as.numeric(year),
week = as.numeric(week)) %>%
rename(week_ending_date = dates)
week_index_calcs = week_index_calcs %>%
left_join(week_end_date)
# Below is code to just calculate one row, the latest week
this_year = format(Sys.Date(), '%Y')
output_table = week_index_calcs %>%
filter(year == this_year) %>%
filter(week == max(week)) %>%
select(week, week_ending_date, weekly_sum_20_jam, weekly_sum_19_jam, change_from_19_jam)
lowest = week_index_calcs %>%
filter((week >= 10 & year == '2020') | year == '2021') %>%
ungroup() %>%
filter(weekly_sum_20_jam == min(weekly_sum_20_jam)) %>%
select(year, week, weekly_sum_20_jam) %>%
rename(year_of_lowest = year,
week_of_lowest = week,
lowest_weekly_sum_20_jam = weekly_sum_20_jam)
peak = week_index_calcs %>%
ungroup() %>%
filter((week >= lowest$week_of_lowest & year == '2020') | year == '2021') %>%
filter(weekly_sum_20_jam == max(weekly_sum_20_jam)) %>%
select(year, week, weekly_sum_20_jam) %>%
rename(year_of_peak = year,
week_of_peak = week,
peak_weekly_sum_20_jam = weekly_sum_20_jam)
output = data.frame(output_table, lowest, peak)
output
output_table
week_index_calcs
View(week_index_calcs)
week_end_date
weeklookup
dates
week
weeklookup
week_end_date
View(weeklookup)
dates
format(dates, '%Y')
weeklookup
sapply(weeklookup, class)
week_end_date = weeklookup %>%
mutate(weekchange = week - lead(week)) %>%
filter(weekchange != 0) %>%
select(-weekchange) %>%
mutate(year = as.numeric(as.character(year)),
week = as.numeric(week)) %>%
rename(week_ending_date = dates)
week_end_date
week_index_calcs = week_index_calcs %>%
left_join(week_end_date)
week_index_calcs
View(week_index_calcs)
View(week_index_calcs)
week_index_calcs <- nw %>%
ungroup() %>%
mutate(
pct_ch_from_prev_week_jam = 100 *  ( (weeksum20_JAM_nf - lag1_weeksum20_JAM_nf) / lag1_weeksum20_JAM_nf ),
pct_ch_from_prev_week_crash = 100 *  ( (weeksum20_ACCIDENT_nf - lag1_weeksum20_ACCIDENT_nf) / lag1_weeksum20_ACCIDENT_nf ),
pct_ch_from_2019_week_jam = 100 *  ( (weeksum20_JAM_nf - weeksum19_JAM_nf) / weeksum19_JAM_nf ),
pct_ch_from_2019_week_crash = 100 *  ( (weeksum20_ACCIDENT_nf - weeksum19_ACCIDENT_nf) / weeksum19_ACCIDENT_nf ),
pct_ch_from_2020bl_week_jam = 100 *  ( (weeksum20_JAM_nf - bl2020_mean_JAM_nf) / bl2020_mean_JAM_nf ),
pct_ch_from_2020bl_week_crash = 100 *  ( (weeksum20_ACCIDENT_nf - bl2020_mean_ACCIDENT_nf) / bl2020_mean_ACCIDENT_nf )
) %>%
group_by(year, week) %>%
summarize(
weekly_sum_20_jam = sum(weeksum20_JAM_nf, na.rm = T),
weekly_sum_19_jam = sum(weeksum19_JAM_nf, na.rm = T),
change_from_19_jam = 100 * (weekly_sum_20_jam - weekly_sum_19_jam) / weekly_sum_19_jam,
pct_ch_from_prev_week_jam = weighted.mean(pct_ch_from_prev_week_jam, w = WoY_Weight_Jams_lag1),
#pct_ch_from_prev_week_crash = weighted.mean(pct_ch_from_prev_week_crash, w = WoY_Weight_Crash_lag1),
pct_ch_from_2019_week_jam = weighted.mean(pct_ch_from_2019_week_jam, w = WoY_Weight_Jams_19),
#pct_ch_from_2019_week_crash = weighted.mean(pct_ch_from_2019_week_crash, w = WoY_Weight_Crash_19),
pct_ch_from_2020bl_week_jam = weighted.mean(pct_ch_from_2020bl_week_jam, w = WoY_Weight_Jams_bl),
#pct_ch_from_2020bl_week_crash = weighted.mean(pct_ch_from_2020bl_week_crash, w = WoY_Weight_Crash_bl),
)
View(week_index_calcs)
week_end_date
week_index_calcs = week_index_calcs %>%
left_join(week_end_date)
View(week_index_calcs)
library(dplyr)
library(ggplot2)
library(ROracle)
library(getPass)
# log into MCMIS
drv <- dbDriver('Oracle')
con <- dbConnect(drv, getPass('username'), getPass('password'),'AIDBDEV')
con <- dbConnect(drv, getPass('username'), getPass('password'),'AIDBDEV')
# Crash Rate Visuals ----
qry <- paste0("SELECT CARRIER_GROUP_ID, COUNT(*) NBR_CARRIER,
ROUND(SUM(CRASH_TOTAL)*100/SUM(ADJUSTED_AVG_PU),2) CRASH_RATE,
ROUND(SUM(fatal_crash_total)*100/SUM(ADJUSTED_AVG_PU),2) FATAL_CRASH_RATE,
ROUND(SUM(inj_crash_total)*100/SUM(ADJUSTED_AVG_PU),2) INJURY_CRASH_RATE,
ROUND(SUM(towaway_crash_total)*100/SUM(ADJUSTED_AVG_PU),2) TOWAWAY_CRASH_RATE
FROM csa.hist_carrier
WHERE released_id = 155
AND dot_number IN (SELECT DOT_NUMBER FROM CC_JOINED_LIST_NACFE
WHERE CR_INCLUDE = 'Y')
AND (CASE WHEN  high_crash_rate = 'N' AND low_crash_rate = 'N' AND pu_to_driver = 'N'
AND pre_pu = 'N' AND post_pu = 'N' AND pre_regulated = 'Y' AND post_regulated = 'Y'
THEN 'Y' ELSE 'N' END) = 'Y'
AND CARRIER_GROUP_ID = 2
AND CARRIER_OPERATION = 'A'
GROUP BY CARRIER_GROUP_ID
ORDER BY CARRIER_GROUP_ID"
)
cr_by_segment <- dbGetQuery(conn = con, statement = qry)
dim(cr_by_segment) #2871   18
names(cr_by_segment)
# Crash Rate Visuals ----
nacfe_dt <- paste0("SELECT 'AF/FE Carriers' POPULATION, DOT_NUMBER, CARRIER_OPERATION,phy_country, LEGAL_NAME, NBR_POWER_UNIT, AVG_POWER_UNIT, ADJUSTED_AVG_PU, RECENT_MILEAGE, INSP_TOTAL,
CRASH_TOTAL,ROUND(CRASH_TOTAL*100/AVG_POWER_UNIT,2) CRASH_RATE, RD_DEFICIENT_TOTAL, SV_DEFICIENT_TOTAL, CARRIER_GROUP_ID, DRIVER_TOTAL,
STRAIGHT_TRUCK_TOTAL, PASSENGER_FLAG, HM_FLAG, HHG_FLAG, HIGH_RISK_FLAG, SAFETY_RATING,
(CASE WHEN round(nvl(AVG_POWER_UNIT,0),0) BETWEEN 0 AND 5 THEN 1
WHEN round(AVG_POWER_UNIT,0) BETWEEN 6 AND 15 THEN 2
WHEN round(AVG_POWER_UNIT,0) BETWEEN 16 AND 50 THEN 3
WHEN round(AVG_POWER_UNIT,0) BETWEEN 51 AND 500 THEN 4
WHEN round(AVG_POWER_UNIT, 0) >= 501  THEN 5
ELSE NULL END) pu_group
FROM csa.hist_carrier
WHERE released_id = 155
AND dot_number IN (SELECT DOT_NUMBER FROM CC_JOINED_LIST_NACFE
WHERE CR_INCLUDE = 'Y')
AND (CASE WHEN  high_crash_rate = 'N' AND low_crash_rate = 'N' AND pu_to_driver = 'N'
AND pre_pu = 'N' AND post_pu = 'N' AND pre_regulated = 'Y' AND post_regulated = 'Y'
THEN 'Y' ELSE 'N' END) = 'Y'
AND CARRIER_OPERATION = 'A'
AND phy_country = 'US'
UNION
SELECT 'Conventional Carriers' POPULATION, DOT_NUMBER, CARRIER_OPERATION, phy_country,LEGAL_NAME, NBR_POWER_UNIT, AVG_POWER_UNIT,ADJUSTED_AVG_PU, RECENT_MILEAGE, INSP_TOTAL,
CRASH_TOTAL,ROUND(CRASH_TOTAL*100/AVG_POWER_UNIT,2) CRASH_RATE, RD_DEFICIENT_TOTAL, SV_DEFICIENT_TOTAL, CARRIER_GROUP_ID, DRIVER_TOTAL,
STRAIGHT_TRUCK_TOTAL, PASSENGER_FLAG, HM_FLAG, HHG_FLAG, HIGH_RISK_FLAG, SAFETY_RATING,
(CASE WHEN round(nvl(AVG_POWER_UNIT,0),0) BETWEEN 0 AND 5 THEN 1
WHEN round(AVG_POWER_UNIT,0) BETWEEN 6 AND 15 THEN 2
WHEN round(AVG_POWER_UNIT,0) BETWEEN 16 AND 50 THEN 3
WHEN round(AVG_POWER_UNIT,0) BETWEEN 51 AND 500 THEN 4
WHEN round(AVG_POWER_UNIT, 0) >= 501  THEN 5
ELSE NULL END) pu_group
FROM csa.hist_carrier
WHERE released_id = 155
AND dot_number NOT IN (SELECT DOT_NUMBER FROM CC_JOINED_LIST_NACFE
WHERE CR_INCLUDE = 'Y')
AND (CASE WHEN  high_crash_rate = 'N' AND low_crash_rate = 'N' AND pu_to_driver = 'N'
AND pre_pu = 'N' AND post_pu = 'N' AND pre_regulated = 'Y' AND post_regulated = 'Y'
THEN 'Y' ELSE 'N' END) = 'Y'
AND CARRIER_OPERATION = 'A'
"
)
# Crash Rate Visuals ----
nacfe_dt_qry <- paste0("SELECT 'AF/FE Carriers' POPULATION, DOT_NUMBER, CARRIER_OPERATION,phy_country, LEGAL_NAME, NBR_POWER_UNIT, AVG_POWER_UNIT, ADJUSTED_AVG_PU, RECENT_MILEAGE, INSP_TOTAL,
CRASH_TOTAL,ROUND(CRASH_TOTAL*100/AVG_POWER_UNIT,2) CRASH_RATE, RD_DEFICIENT_TOTAL, SV_DEFICIENT_TOTAL, CARRIER_GROUP_ID, DRIVER_TOTAL,
STRAIGHT_TRUCK_TOTAL, PASSENGER_FLAG, HM_FLAG, HHG_FLAG, HIGH_RISK_FLAG, SAFETY_RATING,
(CASE WHEN round(nvl(AVG_POWER_UNIT,0),0) BETWEEN 0 AND 5 THEN 1
WHEN round(AVG_POWER_UNIT,0) BETWEEN 6 AND 15 THEN 2
WHEN round(AVG_POWER_UNIT,0) BETWEEN 16 AND 50 THEN 3
WHEN round(AVG_POWER_UNIT,0) BETWEEN 51 AND 500 THEN 4
WHEN round(AVG_POWER_UNIT, 0) >= 501  THEN 5
ELSE NULL END) pu_group
FROM csa.hist_carrier
WHERE released_id = 155
AND dot_number IN (SELECT DOT_NUMBER FROM CC_JOINED_LIST_NACFE
WHERE CR_INCLUDE = 'Y')
AND (CASE WHEN  high_crash_rate = 'N' AND low_crash_rate = 'N' AND pu_to_driver = 'N'
AND pre_pu = 'N' AND post_pu = 'N' AND pre_regulated = 'Y' AND post_regulated = 'Y'
THEN 'Y' ELSE 'N' END) = 'Y'
AND CARRIER_OPERATION = 'A'
AND phy_country = 'US'
UNION
SELECT 'Conventional Carriers' POPULATION, DOT_NUMBER, CARRIER_OPERATION, phy_country,LEGAL_NAME, NBR_POWER_UNIT, AVG_POWER_UNIT,ADJUSTED_AVG_PU, RECENT_MILEAGE, INSP_TOTAL,
CRASH_TOTAL,ROUND(CRASH_TOTAL*100/AVG_POWER_UNIT,2) CRASH_RATE, RD_DEFICIENT_TOTAL, SV_DEFICIENT_TOTAL, CARRIER_GROUP_ID, DRIVER_TOTAL,
STRAIGHT_TRUCK_TOTAL, PASSENGER_FLAG, HM_FLAG, HHG_FLAG, HIGH_RISK_FLAG, SAFETY_RATING,
(CASE WHEN round(nvl(AVG_POWER_UNIT,0),0) BETWEEN 0 AND 5 THEN 1
WHEN round(AVG_POWER_UNIT,0) BETWEEN 6 AND 15 THEN 2
WHEN round(AVG_POWER_UNIT,0) BETWEEN 16 AND 50 THEN 3
WHEN round(AVG_POWER_UNIT,0) BETWEEN 51 AND 500 THEN 4
WHEN round(AVG_POWER_UNIT, 0) >= 501  THEN 5
ELSE NULL END) pu_group
FROM csa.hist_carrier
WHERE released_id = 155
AND dot_number NOT IN (SELECT DOT_NUMBER FROM CC_JOINED_LIST_NACFE
WHERE CR_INCLUDE = 'Y')
AND (CASE WHEN  high_crash_rate = 'N' AND low_crash_rate = 'N' AND pu_to_driver = 'N'
AND pre_pu = 'N' AND post_pu = 'N' AND pre_regulated = 'Y' AND post_regulated = 'Y'
THEN 'Y' ELSE 'N' END) = 'Y'
AND CARRIER_OPERATION = 'A'
"
)
nacfe_dt <- dbGetQuery(conn = con, statement = nacfe_dt_qry)
dim(nacfe_dt) #1,6
names(nacfe_dt)
View(nacfe_dt)
# Crash Rate Visuals ----
nacfe_dt_qry <- paste0("SELECT 'AF/FE Carriers' POPULATION, DOT_NUMBER, CARRIER_OPERATION,phy_country, LEGAL_NAME, NBR_POWER_UNIT, AVG_POWER_UNIT, ADJUSTED_AVG_PU, RECENT_MILEAGE, INSP_TOTAL,
CRASH_TOTAL,fatal_crash_total, inj_crash_total, towaway_crash_total, ROUND(CRASH_TOTAL*100/AVG_POWER_UNIT,2) CRASH_RATE, RD_DEFICIENT_TOTAL, SV_DEFICIENT_TOTAL, CARRIER_GROUP_ID, DRIVER_TOTAL,
STRAIGHT_TRUCK_TOTAL, PASSENGER_FLAG, HM_FLAG, HHG_FLAG, HIGH_RISK_FLAG, SAFETY_RATING,
(CASE WHEN round(nvl(AVG_POWER_UNIT,0),0) BETWEEN 0 AND 5 THEN 1
WHEN round(AVG_POWER_UNIT,0) BETWEEN 6 AND 15 THEN 2
WHEN round(AVG_POWER_UNIT,0) BETWEEN 16 AND 50 THEN 3
WHEN round(AVG_POWER_UNIT,0) BETWEEN 51 AND 500 THEN 4
WHEN round(AVG_POWER_UNIT, 0) >= 501  THEN 5
ELSE NULL END) pu_group
FROM csa.hist_carrier
WHERE released_id = 155
AND dot_number IN (SELECT DOT_NUMBER FROM CC_JOINED_LIST_NACFE
WHERE CR_INCLUDE = 'Y')
AND (CASE WHEN  high_crash_rate = 'N' AND low_crash_rate = 'N' AND pu_to_driver = 'N'
AND pre_pu = 'N' AND post_pu = 'N' AND pre_regulated = 'Y' AND post_regulated = 'Y'
THEN 'Y' ELSE 'N' END) = 'Y'
AND CARRIER_OPERATION = 'A'
AND phy_country = 'US'
UNION
SELECT 'Conventional Carriers' POPULATION, DOT_NUMBER, CARRIER_OPERATION, phy_country,LEGAL_NAME, NBR_POWER_UNIT, AVG_POWER_UNIT,ADJUSTED_AVG_PU, RECENT_MILEAGE, INSP_TOTAL,
CRASH_TOTAL,ROUND(CRASH_TOTAL*100/AVG_POWER_UNIT,2) CRASH_RATE, RD_DEFICIENT_TOTAL, SV_DEFICIENT_TOTAL, CARRIER_GROUP_ID, DRIVER_TOTAL,
STRAIGHT_TRUCK_TOTAL, fatal_crash_total, inj_crash_total, towaway_crash_total,PASSENGER_FLAG, HM_FLAG, HHG_FLAG, HIGH_RISK_FLAG, SAFETY_RATING,
(CASE WHEN round(nvl(AVG_POWER_UNIT,0),0) BETWEEN 0 AND 5 THEN 1
WHEN round(AVG_POWER_UNIT,0) BETWEEN 6 AND 15 THEN 2
WHEN round(AVG_POWER_UNIT,0) BETWEEN 16 AND 50 THEN 3
WHEN round(AVG_POWER_UNIT,0) BETWEEN 51 AND 500 THEN 4
WHEN round(AVG_POWER_UNIT, 0) >= 501  THEN 5
ELSE NULL END) pu_group
FROM csa.hist_carrier
WHERE released_id = 155
AND dot_number NOT IN (SELECT DOT_NUMBER FROM CC_JOINED_LIST_NACFE
WHERE CR_INCLUDE = 'Y')
AND (CASE WHEN  high_crash_rate = 'N' AND low_crash_rate = 'N' AND pu_to_driver = 'N'
AND pre_pu = 'N' AND post_pu = 'N' AND pre_regulated = 'Y' AND post_regulated = 'Y'
THEN 'Y' ELSE 'N' END) = 'Y'
AND CARRIER_OPERATION = 'A'
"
)
nacfe_dt <- dbGetQuery(conn = con, statement = nacfe_dt_qry)
dim(nacfe_dt) #387082/23
names(nacfe_dt)
write.csv(nacfe_dt, file = 'C:/Users/Jessie.Yang.CTR/Downloads/2022 Projects/NHTSA AF FE Safety Project/nacfe_dt.csv')
